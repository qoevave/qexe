"use strict";(self.webpackChunkqexe_website=self.webpackChunkqexe_website||[]).push([[9969],{8995:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>u,frontMatter:()=>a,metadata:()=>d,toc:()=>c});var o=i(4848),s=i(8453);const a={sidebar_position:4,custom_edit_url:null,description:"Creating your evaluation scenes..."},t="Evaluation Scenes",d={id:"getting-started/eval-scenes",title:"Evaluation Scenes",description:"Creating your evaluation scenes...",source:"@site/docs/getting-started/eval-scenes.mdx",sourceDirName:"getting-started",slug:"/getting-started/eval-scenes",permalink:"/qexe/docs/getting-started/eval-scenes",draft:!1,unlisted:!1,editUrl:null,tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4,custom_edit_url:null,description:"Creating your evaluation scenes..."},sidebar:"tutorialSidebar",previous:{title:"Scene Types",permalink:"/qexe/docs/getting-started/scene-types"},next:{title:"Download",permalink:"/qexe/docs/downloading"}},l={},c=[{value:"Making an Evaluation Scene",id:"making-an-evaluation-scene",level:2},{value:"Object-based Audio + CGI",id:"object-based-audio--cgi",level:3},{value:"Object-based + 360 Video",id:"object-based--360-video",level:3},{value:"Ambisonics audio + 360 Video",id:"ambisonics-audio--360-video",level:3},{value:"Ambisoncs audio + CGI",id:"ambisoncs-audio--cgi",level:3}];function r(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"evaluation-scenes",children:"Evaluation Scenes"}),"\n",(0,o.jsx)(n.h2,{id:"making-an-evaluation-scene",children:"Making an Evaluation Scene"}),"\n",(0,o.jsxs)(n.p,{children:["Scenes are defined in the ",(0,o.jsx)(n.a,{href:"/qexe/docs/getting-started/config-file",children:"configuration file"})," using a set of identifiers, parameters, and audio and visual material."]}),"\n",(0,o.jsx)(n.h3,{id:"object-based-audio--cgi",children:"Object-based Audio + CGI"}),"\n",(0,o.jsx)(n.p,{children:"Here's an example scene configuration for a CGI scene. The evaluation scene uses individual audio files which are associated with audio objects in virtual reality, and are rendered using an object-based audio workflow."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-JSON",children:'"Scenes" : [\n    {\n        "stimuli_ID" : "Scene_stereo_bongos_interaction",\n        "unityScene_ID" : "_bongos_demo",\n        "visualStimuliType" : "CGI",\n        "dimensions" : [ 30.0, 8.0, 30.0 ],\n        "multichannelAudio" : {\n            "multichannelAudioFile" : null\n        },\n        "objectAudio" : {\n            "objectAudioFolder" : "audio/_bongos/edited",\n            "objectAudioRouting" : [\n                {\n                    "pathToFile" : "1_bongos_L.wav",\n                    "inputChannel" : 0,\n                    "autoplay" : 1\n                },\n                {\n                    "pathToFile" : "2_bongos_R.wav",\n                    "inputChannel" : 1,\n                    "autoplay" : 1\n                }\n            ]\n        }\n    }\n]\n'})}),"\n",(0,o.jsx)(n.p,{children:"Let's break it down..."}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"scene_ID"}),' \u2192 A string to define the test item (e.g., "Scene_stereo_bongos_interaction", to help us identify certain aspects of the item quickly)']}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"unityScene_ID"})," \u2192 A string entry used to inform the Unity client which Unity scene should be loaded"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"VisualStimuli"})," \u2192 Either ",(0,o.jsx)(n.code,{children:"CGI"})," or ",(0,o.jsx)(n.code,{children:"ODV"})," entry to determine which further config entries are of interest"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"dimensions"})," \u2192 X, Z, Y dimensions of the virtual scene, used for paramater input normalizion for VSTs"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"multichannelAudioFile"})," \u2192 path to the multichannel audio file(s)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"objectAudioFolder"})," \u2192 path to the folder containing the mono audio files used for audio objects"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"objectAudioRouting"})," \u2192 An array entry of nested data regarding specific audio files. For each audio file, we provide","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"pathToFile"})," \u2192  name/path of the audio file relative to the audio ",(0,o.jsx)(n.code,{children:"objectAudioFolder"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"inputChannel"})," \u2192 input channel to the VST"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"autoplay"})," \u2192 ",(0,o.jsx)(n.code,{children:"1"})," or ",(0,o.jsx)(n.code,{children:"0"})," to say if the file should continuously loop from start or be triggered by event"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"object-based--360-video",children:"Object-based + 360 Video"}),"\n",(0,o.jsx)(n.p,{children:"An example using a 360 which has been augments by audio objects with the object rendering pipeline."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-JSON",children:'"audioRendering" : {\n    ...\n    "renderingPipeline" : "Objects",\n    ...\n},\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-JSON",children:'"Scenes" : [\n    {\n        "scene_ID" : "Scene_sax_video_audio_object",\n        //highlight-start\n        "unityScene_ID" : "_videoPlayer", // <- Specific scene for video playabck.\n        "visualStimuliType" : "ODV",\n        "videoFiles" : [ // <- List allows multiple video files per scene.\n            {\n                "pathToFile" : "saxophone/video/saxophonePlayer.mp4", \n                "video_ID" : 1\n            }\n        ],\n        //highlight-end\n        "dimensions" : [ 5, 5, 5 ], \n        "multichannelAudio" : {\n            "multichannelAudioFile" : null\n        },\n        "objectAudio" : {\n            "objectAudioFolder" : "saxophone/objects",\n            "objectAudioRouting" : [\n                {\n                    "pathToFile" : "saxophone.wav",\n                    "inputChannel" : 0,\n                    "autoplay" : 1\n                }\n            ]\n        }\n    }\n]\n'})}),"\n",(0,o.jsx)(n.p,{children:"A scene that is recorded via a 360 camera doesn't change in terms of the content that is recorded. However, it CAN change in terms of encoding, resolution, or frame-rate, for example. Therefore, multiple recordings can be classified as the same scene."}),"\n",(0,o.jsxs)(n.p,{children:["Allowing multiple video files to be assigned to a single scene is an efficient way of creating test items for ",(0,o.jsx)(n.a,{href:"/qexe/docs/features/methods",children:"ACR"})," video quality evaluation, where all other parameters would remain the same."]}),"\n",(0,o.jsx)(n.h3,{id:"ambisonics-audio--360-video",children:"Ambisonics audio + 360 Video"}),"\n",(0,o.jsx)(n.p,{children:"An example using the multichannel rendering pipline with Ambisoncis audio and 360 video..."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-JSON",children:'"audioRendering" : {\n    ...\n    "renderingPipeline" : "Multichannel", // <- Set rendering pipeline for Multichannel audio.\n    ...\n},\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-JSON",children:'"Scenes" : [\n    {\n        "scene_ID" : "Scene_sax_video_audio_object",\n        "unityScene_ID" : "_videoPlayer", // <- Specific scene for video playabck.\n        "visualStimuliType" : "ODV",\n        "videoFiles" : [ // <- List allows multiple video files per scene.\n            {\n                "pathToFile" : "saxophone/video/saxophonePlayer.mp4", \n                "video_ID" : 1\n            }\n        ],\n        "dimensions" : [ 5, 5, 5 ], // <- This is ignored in multichannel audio rendering\n        //highlight-start\n        "multichannelAudio" : {\n            "multichannelAudioFile" : "saxophone/ambisonics/4OA_Saxophone.wav"\n        },\n        //highlight-end\n        "objectAudio" : {\n            "objectAudioFolder" : "null",\n            "objectAudioRouting" : [ ]\n        }\n    }\n]\n'})}),"\n",(0,o.jsx)(n.p,{children:"Here, we've removed information regarding audio objects and object routing, and have inlcuded a path to the Ambisonics audio file."}),"\n",(0,o.jsx)(n.h3,{id:"ambisoncs-audio--cgi",children:"Ambisoncs audio + CGI"}),"\n",(0,o.jsx)(n.p,{children:"An example using a CGI scene and Ambisonics audio"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-JSON",children:'"audioRendering" : {\n    ...\n    "renderingPipeline" : "Multichannel", // <- Set rendering pipeline for Multichannel audio.\n    ...\n},\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-JSON",children:'"Scenes" : [\n    {\n        "scene_ID" : "Scene_city_1OA_audio",\n        "unityScene_ID" : "_city",\n        "visualStimuli" : "CGI",\n        "dimensions" : [ 50.0, 8.0, 50.0 ],\n        "multichannelAudio" : {\n            "multichannelAudioFile" : "city/ambisonics/4OA_City.wav"\n        },\n        "objectAudio" : {\n            "objectAudioFolder" : "null",\n            "objectAudioRouting" : [ ]\n        }\n    }\n]\n'})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(r,{...e})}):r(e)}}}]);